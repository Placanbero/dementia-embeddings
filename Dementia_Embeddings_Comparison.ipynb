{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BhWiXxK3cWaz",
        "n_5zX1U662Xn",
        "6zsK3EAXt8E-",
        "R0NGAylhy_p1",
        "DFU-AHpz5lH_",
        "7gvyoG4bcT1s",
        "xMToTB3Ej_1P",
        "uu15FKZZlxHv",
        "45a8DVfG8CXT",
        "IAuFJshV57G7",
        "el22seB3sZ76",
        "R8t1Xk_aznbJ",
        "5JbbBbcnXpx2",
        "hISbTMTcbAMO",
        "LG69OX12dp4t"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "BhWiXxK3cWaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Path to Dataset Folder"
      ],
      "metadata": {
        "id": "n_5zX1U662Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the dataset folder\n",
        "# IMPORTANT: Modify this path to point to your local copy of the Pitt Corpus database.\n",
        "folder_path = '/path/to/PittCorpus'\n",
        "\n",
        "# Note: Ensure that the dataset has the expected folder structure (e.g., 'Transcripts/Control/...')."
      ],
      "metadata": {
        "id": "joA5gIwYIlM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Functions\n",
        "\n",
        "The following functions perform various pipelines of text cleaning, extraction, and symbol replacement tailored to the CHAT format of the Pitt Corpus. These preprocessing steps are essential to normalize and structure the transcript data before further analysis.\n"
      ],
      "metadata": {
        "id": "6zsK3EAXt8E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "7INdHOmZuSD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = str(text).lower()\n",
        "    # Remove timing markers (e.g., 30_5640)\n",
        "    text = re.sub(r'\\d+_\\d+', '', text)\n",
        "    # Remove headers like %wor, %mor, %gra, and *PAR:\n",
        "    text = re.sub(r'(%wor|%mor|%gra|\\*par):', '', text)\n",
        "    # Remove morphological tags (e.g., det:art|the n|scene)\n",
        "    text = re.sub(r'\\b\\w+:\\w+\\|\\w+', '', text)\n",
        "    # Remove special symbol ‡\n",
        "    text = text.replace('‡', '')\n",
        "    # Remove specific annotations like [+ exc]\n",
        "    text = re.sub(r'\\[\\+ exc\\]', '', text)\n",
        "    # Remove researcher intervention marker +<\n",
        "    text = re.sub(r'\\+<\\s*', '', text)\n",
        "    # Preserve [+ gram], remove other similar annotations\n",
        "    text = re.sub(r'\\[\\+ gram\\]', '[+ gram]', text)\n",
        "    text = re.sub(r'&\\S+', '', text)  # Remove morphological analyses like y&...\n",
        "    # Remove tabs and normalize whitespace\n",
        "    text = text.replace('\\t', ' ').replace('  ', ' ')\n",
        "    # Fix spacing before punctuation\n",
        "    text = re.sub(r'\\s+([.?])', r'\\1', text)\n",
        "    text = re.sub(r'\\s+(\\?)', r'\\1', text)\n",
        "    # Final cleanup of extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "4G00ubrD6QiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_words_only(text):\n",
        "    # Convert to lowercase\n",
        "    text = str(text).lower()\n",
        "    # Remove timing and label markers\n",
        "    text = re.sub(r'\\d+_\\d+', '', text)\n",
        "    text = re.sub(r'(%\\w+:|\\*par:)', '', text)\n",
        "    text = re.sub(r'\\b\\w+:\\w+\\|\\w+', '', text)\n",
        "    # Remove special characters and punctuation\n",
        "    text = re.sub(r'[<>\\[\\]\\(\\)\\{\\}/\\\\]', '', text)\n",
        "    text = re.sub(r'\\+[^ ]*', '', text)\n",
        "    text = re.sub(r'&\\S+', '', text)\n",
        "    text = re.sub(r'[.,!?]', '', text)\n",
        "    # Keep only letters and spaces\n",
        "    text = re.sub(r'[^a-záéíóúüñ\\s]', '', text)\n",
        "    # Normalize spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "AWf_9w1_ZfPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_without_special_symbols(text):\n",
        "    # Convert to lowercase\n",
        "    text = str(text).lower()\n",
        "    # Remove timing and label markers\n",
        "    text = re.sub(r'\\d+_\\d+', '', text)\n",
        "    text = re.sub(r'(%\\w+:|\\*par:)', '', text)\n",
        "    text = re.sub(r'\\b\\w+:\\w+\\|\\w+', '', text)\n",
        "    # Remove special symbols\n",
        "    text = re.sub(r'<[^>]+>', '', text)        # Remove content between <>\n",
        "    text = re.sub(r'\\([^)]*\\)', '', text)      # Remove content between ()\n",
        "    text = re.sub(r'\\[[^\\]]*\\]', '', text)     # Remove content between []\n",
        "    text = re.sub(r'\\+[^ ]*', '', text)        # Remove + prefixed codes\n",
        "    text = re.sub(r'&\\S+', '', text)           # Remove & codes\n",
        "    # Normalize spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n"
      ],
      "metadata": {
        "id": "xF7zgzsvZgL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_symbols(text):\n",
        "    # Replace symbols with corresponding English words\n",
        "    text = re.sub(r'\\[/\\]', 'pause', text)\n",
        "    text = re.sub(r'\\[//\\]', 'long pause', text)\n",
        "    text = re.sub(r'<[^>]+>', 'correction', text)\n",
        "    text = re.sub(r'\\(\\.\\.\\.\\)', 'mispronunciation', text)\n",
        "    text = re.sub(r'\\[\\+ gram\\]', 'grammatical error', text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "GlAdrGH9CJGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_cha_info(folder_path):\n",
        "    cha_files = []\n",
        "    diagnoses = []\n",
        "    raw_texts = []\n",
        "    cleaned_texts = []\n",
        "\n",
        "    # Process both Control and Dementia subfolders\n",
        "    for subfolder in ['Control/cookie', 'Dementia/cookie']:\n",
        "        full_path = os.path.join(folder_path, subfolder)\n",
        "        for filename in os.listdir(full_path):\n",
        "            if filename.endswith('.cha'):\n",
        "                file_path = os.path.join(full_path, filename)\n",
        "                with open(file_path, 'r') as f:\n",
        "                    content = f.read()\n",
        "                    # Extract diagnosis from @ID line\n",
        "                    id_line = [line for line in content.splitlines() if line.startswith('@ID')][0]\n",
        "                    diagnosis = id_line.split('|')[5]\n",
        "                    # Extract patient's speech\n",
        "                    patient_text = ' '.join([line for line in content.splitlines() if line.startswith('*PAR:')])\n",
        "                    # Clean the text\n",
        "                    cleaned_text = clean_text(patient_text)\n",
        "                    # Optionally, try other cleaning functions:\n",
        "                    # cleaned_text = replace_symbols(patient_text)\n",
        "                    # cleaned_text = clean_words_only(patient_text)\n",
        "                    # cleaned_text = clean_without_special_symbols(patient_text)\n",
        "                    # Store all information\n",
        "                    cha_files.append(filename)\n",
        "                    diagnoses.append(diagnosis)\n",
        "                    raw_texts.append(patient_text)\n",
        "                    cleaned_texts.append(cleaned_text)\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file': cha_files,\n",
        "        'diagnosis': diagnoses,\n",
        "        'raw_text': raw_texts,\n",
        "        'cleaned_text': cleaned_texts\n",
        "    })\n",
        "\n",
        "    # Convert diagnosis column to one-hot encoding\n",
        "    diagnosis_one_hot = pd.get_dummies(df['diagnosis'], prefix='diagnosis')\n",
        "    df = pd.concat([df, diagnosis_one_hot], axis=1)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "iLO4-aCAni3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Preparation\n",
        "\n",
        "This section loads the CHAT files, constructs the initial DataFrame, and applies basic preprocessing such as filtering classes and mapping diagnosis labels into binary categories for classification tasks.\n"
      ],
      "metadata": {
        "id": "R0NGAylhy_p1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcripts_path = f'{folder_path}/Transcripts'\n",
        "df_transcripts = extract_cha_info(transcripts_path)\n"
      ],
      "metadata": {
        "id": "mK0hwCjYoWd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort transcripts by filename\n",
        "df_transcripts = df_transcripts.sort_values(by='file')\n"
      ],
      "metadata": {
        "id": "2C-LQ2ST0pdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count samples per diagnosis\n",
        "class_counts = df_transcripts['diagnosis'].value_counts()\n",
        "\n",
        "# Keep only classes with at least 2 samples\n",
        "df_transcripts_filtered = df_transcripts[df_transcripts['diagnosis'].isin(class_counts[class_counts >= 2].index)].copy()\n"
      ],
      "metadata": {
        "id": "18il2ugbDpqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a binary label column: 0 = Control, 1 = ProbableAD or PossibleAD, -1 = other\n",
        "df_transcripts_filtered['global_diagnosis'] = df_transcripts_filtered['diagnosis'].apply(lambda x: 0 if x == 'Control' else 1 if x in ['ProbableAD', 'PossibleAD'] else -1)"
      ],
      "metadata": {
        "id": "51319ihuZUf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define label names for reporting\n",
        "label_map = {0: \"Control\", 1: \"Alzheimer's Indicator\"}"
      ],
      "metadata": {
        "id": "obDstr8-PRgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminary Analysis of BERT Configurations"
      ],
      "metadata": {
        "id": "DFU-AHpz5lH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contextual Word Embeddings (BERT) Configurations\n",
        "\n",
        "This section compares different strategies for generating sentence-level embeddings from BERT to evaluate their impact on classification performance. Three methods are explored:\n",
        "\n",
        "- **Mean of token embeddings**: averaging all token embeddings to represent the sentence.\n",
        "- **[CLS] token embedding**: using the special classification token provided by BERT as a summary of the sentence.\n",
        "- **Concatenation of the last four hidden layers**: representation that stacks information from multiple depths of the model.\n",
        "\n",
        "All configurations are evaluated on the same train–test split to ensure comparability."
      ],
      "metadata": {
        "id": "7gvyoG4bcT1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Additional libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "plt.rcParams.update({'font.size': 16})\n",
        "plt.rcParams.update({'figure.figsize': [10, 6]})\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n"
      ],
      "metadata": {
        "id": "b26crY9Fc0zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT-base tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load BERT-large tokenizer and model\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
        "# model = BertModel.from_pretrained('bert-large-uncased')\n"
      ],
      "metadata": {
        "id": "mn-FTeuIc4Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Filter for binary classification (Control vs Alzheimer's)\n",
        "df_filtered = df_transcripts_filtered[df_transcripts_filtered['global_diagnosis'].isin([0, 1])]\n",
        "\n",
        "# Define X and y\n",
        "X = df_filtered['cleaned_text']\n",
        "y = df_filtered['global_diagnosis']\n",
        "\n",
        "# Stratified train-test split\n",
        "train_text, test_text, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "iABomJ6m_EYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore training set and test set label class distribution\n",
        "print(\"Training set label distribution:\\n\", y_train.value_counts())\n",
        "print(\"Test set label distribution:\\n\", y_test.value_counts())\n"
      ],
      "metadata": {
        "id": "DBbzzZ7Dbhcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set sentence embeddings using mean of token embeddings\n",
        "bert_sent_embeddings_train=[]\n",
        "for text in train_text:\n",
        "  encoding = tokenizer.batch_encode_plus([text],  # List of input texts\n",
        "    padding=True,                                 # Pad to the maximum sequence length\n",
        "    truncation=True,                              # Truncate if input exceeds the maximum length\n",
        "    return_tensors='pt',                          # Return PyTorch tensors\n",
        "    add_special_tokens=True)                      # Add special CLS and SEP tokens\n",
        "  input_ids = encoding['input_ids']               # Token identifiers\n",
        "  attention_mask = encoding['attention_mask']     # Attention mask\n",
        "  # Generate training set embeddings using the BERT model\n",
        "  with torch.no_grad():\n",
        "      outputs = model(input_ids, attention_mask=attention_mask)\n",
        "      word_embeddings = outputs.last_hidden_state\n",
        "  sentence_embedding = word_embeddings.mean(dim=1)\n",
        "  bert_sent_embeddings_train.append(sentence_embedding[0])"
      ],
      "metadata": {
        "id": "tfLMGSTvcENb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set sentence embeddings using the [CLS] token (designed to summarize full sequence)\n",
        "bert_sent_embeddings_train=[]\n",
        "for text in train_text:\n",
        "  encoding = tokenizer.batch_encode_plus([text],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt',\n",
        "    add_special_tokens=True)\n",
        "  input_ids = encoding['input_ids']\n",
        "  attention_mask = encoding['attention_mask']\n",
        "  with torch.no_grad():\n",
        "      outputs = model(input_ids, attention_mask=attention_mask)\n",
        "      cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "  bert_sent_embeddings_train.append(cls_embedding[0].numpy())\n",
        "\n",
        "bert_sent_embeddings_train=np.array(bert_sent_embeddings_train)"
      ],
      "metadata": {
        "id": "KXOaKIXmS8XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set sentence embeddings using concatenation of the last 4 hidden layers\n",
        "bert_sent_embeddings_train = []\n",
        "for text in train_text:\n",
        "  encoding = tokenizer.batch_encode_plus([text],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt',\n",
        "    add_special_tokens=True)\n",
        "  input_ids = encoding['input_ids']\n",
        "  attention_mask = encoding['attention_mask']\n",
        "  with torch.no_grad():\n",
        "      outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "      hidden_states = outputs.hidden_states\n",
        "      concat_last_4 = torch.cat(hidden_states[-4:], dim=-1)\n",
        "      sentence_embedding = concat_last_4.mean(dim=1)\n",
        "  bert_sent_embeddings_train.append(sentence_embedding[0])\n"
      ],
      "metadata": {
        "id": "Rsm1d8_WuYUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set sentence embeddings using the mean of token embeddings\n",
        "# For CLS token or last-4-layer concatenation, replicate the approach used in the training set accordingly\n",
        "bert_sent_embeddings_test=[]\n",
        "for text in test_text:\n",
        "  encoding = tokenizer.batch_encode_plus( [text],   # List of input texts\n",
        "    padding=True,                                   # Pad to the maximum sequence length\n",
        "    truncation=True,                                # Truncate if input exceeds the maximum length\n",
        "    return_tensors='pt',                            # Return PyTorch tensors\n",
        "    add_special_tokens=True)                        # Add special CLS and SEP tokens\n",
        "  input_ids = encoding['input_ids']                 # Token identifiers\n",
        "  attention_mask = encoding['attention_mask']       # Attention mask\n",
        "  # Generate test set embeddings using the BERT model\n",
        "  with torch.no_grad():\n",
        "      outputs = model(input_ids, attention_mask=attention_mask)\n",
        "      word_embeddings = outputs.last_hidden_state\n",
        "  sentence_embedding = word_embeddings.mean(dim=1)\n",
        "  bert_sent_embeddings_test.append(sentence_embedding[0])"
      ],
      "metadata": {
        "id": "Dy7Fs2Xcm2kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Fit logistic regression (balanced for class imbalance)\n",
        "log_reg_model = LogisticRegression(class_weight='balanced', solver='lbfgs', max_iter=1000)\n",
        "log_reg_model.fit(bert_sent_embeddings_train, y_train)"
      ],
      "metadata": {
        "id": "FoisR4GOfUlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predicted = log_reg_model.predict(bert_sent_embeddings_test)"
      ],
      "metadata": {
        "id": "QT5ta1amfxsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the logistic regression model trained with BERT embeddings\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(y_test, predicted, target_names=[\"Control\", \"Alzheimer's Indicator\"]))"
      ],
      "metadata": {
        "id": "tHOCLoJ0f0CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "conf_matrix = metrics.confusion_matrix(y_test, predicted)\n",
        "labels = [label_map[i] for i in np.unique(y_test)]\n",
        "df_cm = pd.DataFrame(conf_matrix, columns=labels, index=labels)\n",
        "\n",
        "# Axis labels\n",
        "df_cm.index.name = 'Ground Truth Labels'\n",
        "df_cm.columns.name = 'Predicted Labels'\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sn.set(font_scale=1.4)\n",
        "sn.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt='g', annot_kws={\"size\": 20})\n",
        "plt.title('Confusion Matrix - BERT embeddings')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gBgRyScJgZjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tf-Idf\n",
        "\n",
        "As part of the preliminary comparison, a traditional Tf-Idf approach was also evaluated using the same train–test split applied in the BERT configuration experiments.\n"
      ],
      "metadata": {
        "id": "xMToTB3Ej_1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate a logistic regression classifier using a Tf-Idf feature representation\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "text_clf=Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', LogisticRegression(class_weight='balanced',solver='lbfgs',max_iter=1000)),])\n"
      ],
      "metadata": {
        "id": "fI5Z0iPLkDhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the pipeline model\n",
        "text_clf.fit(train_text, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_tf_idf = text_clf.predict(test_text)"
      ],
      "metadata": {
        "id": "w66z71YdkOhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute model accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred_tf_idf)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "DX8RFGFTkVYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate logistic regression model trained using TF-IDF\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(y_test, y_pred_tf_idf, target_names=[\"Control\", \"Alzheimer's Indicator\"]))\n"
      ],
      "metadata": {
        "id": "iOKCCbhnkbnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "conf_matrix_tf_idf = metrics.confusion_matrix(y_test, y_pred_tf_idf)\n",
        "labels = [label_map[i] for i in np.unique(y_test)]\n",
        "df_cm = pd.DataFrame(conf_matrix_tf_idf, columns=labels, index=labels)\n",
        "\n",
        "# Axis labels\n",
        "df_cm.index.name = 'Ground Truth Labels'\n",
        "df_cm.columns.name = 'Predicted Labels'\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sn.set(font_scale=1.4)\n",
        "sn.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt='g', annot_kws={\"size\": 20})\n",
        "plt.title('Confusion Matrix - Tf-Idf')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MJNCXRtUktE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-Contextual Word Embeddings (GloVe)\n",
        "\n",
        "To complement the preliminary comparison, a non-contextual embedding method based on pre-trained GloVe vectors (300-dimensional) was also evaluated using the same train–test split used in the BERT configuration experiments."
      ],
      "metadata": {
        "id": "uu15FKZZlxHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GloVe word embeddings from file\n",
        "import numpy as np\n",
        "nltk.download('stopwords')  # Download stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "embeddings_index = {}\n",
        "# IMPORTANT: Modify this path to point to your local copy of the GloVe embeddings file (300-dimensional)\n",
        "f = open('/path/to/Glove/glove300.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "id": "6cax6xtPl1cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate sentence embeddings from word embeddings\n",
        "def sent2vec(s):\n",
        "    words = str(s).lower()\n",
        "    words = word_tokenize(words)\n",
        "    words = [w for w in words if w not in stop_words]  # Remove stopwords\n",
        "    M = []\n",
        "    for w in words:\n",
        "        try:\n",
        "            M.append(embeddings_index[w])  # Append the word embedding\n",
        "        except:\n",
        "            continue\n",
        "    M = np.array(M)\n",
        "    v = M.sum(axis=0)\n",
        "    if type(v) != np.ndarray:\n",
        "        return np.zeros(300)\n",
        "    return v / np.sqrt((v ** 2).sum())\n"
      ],
      "metadata": {
        "id": "Nvv8c2gwl3nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sentence embeddings for the dataset using the function above\n",
        "from tqdm import tqdm\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "xtrain_glove = [sent2vec(x) for x in tqdm(train_text)]\n",
        "xtest_glove = [sent2vec(x) for x in tqdm(test_text)]\n"
      ],
      "metadata": {
        "id": "cEjekpvjl5Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain_glove = np.array(xtrain_glove)\n",
        "xtest_glove = np.array(xtest_glove)"
      ],
      "metadata": {
        "id": "gyMW__e0l7Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train logistic regression model on the GloVe sentence embeddings\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg_model = LogisticRegression(class_weight='balanced',solver='lbfgs',max_iter=1000)\n",
        "log_reg_model.fit(xtrain_glove, y_train)"
      ],
      "metadata": {
        "id": "jLToWUKJl9E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predicted_glove = log_reg_model.predict(xtest_glove)\n"
      ],
      "metadata": {
        "id": "vsrjOL_ql-zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the logistic regression model trained with GloVe embeddings\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(y_test, predicted_glove, target_names=[\"Control\", \"Alzheimer's Indicator\"]))\n"
      ],
      "metadata": {
        "id": "wkH7WYrqmCF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "conf_matrix_glove = metrics.confusion_matrix(y_test, predicted_glove)\n",
        "labels = [label_map[i] for i in np.unique(y_test)]\n",
        "df_cm = pd.DataFrame(conf_matrix_glove, columns=labels, index=labels)\n",
        "\n",
        "# Axis labels\n",
        "df_cm.index.name = 'Ground Truth Labels'\n",
        "df_cm.columns.name = 'Predicted Labels'\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sn.set(font_scale=1.4)\n",
        "sn.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt='g', annot_kws={\"size\": 20})\n",
        "plt.title('Confusion Matrix - GloVe embeddings')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "noD6XWYwmGyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gemma-2B\n",
        "\n",
        "In this subsection, the performance of sentence embeddings obtained from the Gemma-2B language model is evaluated, using the same train–test split applied in the previous BERT configuration experiments. The Gemma-2B model, developed by Google, is available via Hugging Face upon request and can be used through the `transformers` library for embedding generation."
      ],
      "metadata": {
        "id": "45a8DVfG8CXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "id": "m5Jm8YY48RuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "2X2l1MMf8V1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "model_name = \"google/gemma-2b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "W03gA9K18dMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Generate sentence embeddings using Gemma-2B for the training set\n",
        "embeddings_gemma = []\n",
        "for i, text in enumerate(train_text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling for sentence embedding\n",
        "    embeddings_gemma.append(embeddings[0])\n"
      ],
      "metadata": {
        "id": "OXCxI0DY8hq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sentence embeddings using Gemma-2B for the test set\n",
        "embeddings_gemma_test = []\n",
        "for i, text in enumerate(test_text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling for sentence embedding\n",
        "    embeddings_gemma_test.append(embeddings[0])\n"
      ],
      "metadata": {
        "id": "gP5vlaZm9jrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train logistic regression model on the Gemma-2B sentence embeddings\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg_model_gemma = LogisticRegression(class_weight='balanced',solver='lbfgs',max_iter=1000)\n",
        "log_reg_model_gemma.fit(embeddings_gemma, y_train)"
      ],
      "metadata": {
        "id": "B6nZrHcX-Ekw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predicted_gemma = log_reg_model_gemma.predict(embeddings_gemma_test)\n"
      ],
      "metadata": {
        "id": "vaSqToWr-7Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the logistic regression model trained with Gemma-2B embeddings\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(y_test, predicted_gemma, target_names=[\"Control\", \"Alzheimer's Indicator\"]))\n"
      ],
      "metadata": {
        "id": "ADpvDq_F_iz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "conf_matrix_gemma = metrics.confusion_matrix(y_test, predicted_gemma)\n",
        "labels = [label_map[i] for i in np.unique(y_test)]\n",
        "df_cm_gemma = pd.DataFrame(conf_matrix_gemma, columns=labels, index=labels)\n",
        "\n",
        "# Axis labels\n",
        "df_cm_gemma.index.name = 'Ground Truth Labels'\n",
        "df_cm_gemma.columns.name = 'Predicted Labels'\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sn.set(font_scale=1.4)\n",
        "sn.heatmap(df_cm_gemma, cmap=\"Blues\", annot=True, fmt='g', annot_kws={\"size\": 20})\n",
        "plt.title('Confusion Matrix - Gemma-2B embeddings')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mw10S68e_7pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Five-Fold Cross-Validation Analysis"
      ],
      "metadata": {
        "id": "IAuFJshV57G7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common Setup for K-Fold Cross-Validation\n",
        "\n",
        "This section prepares the data for the 5-fold stratified cross-validation procedure used consistently across all embedding methods in the subsequent experiments. The same splits are used to evaluate all methods to ensure fair and reproducible comparison.\n"
      ],
      "metadata": {
        "id": "el22seB3sZ76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Filter the dataset to include only Control (0) and Alzheimer's Indicator (1) diagnoses\n",
        "df_kfold = df_transcripts_filtered[df_transcripts_filtered['global_diagnosis'].isin([0, 1])]\n",
        "\n",
        "# Define the common input (X) and label (y) sets, maintaining original order\n",
        "X_common = df_kfold['cleaned_text']\n",
        "y_common = df_kfold['global_diagnosis']\n",
        "\n",
        "# Configure 5-fold stratified cross-validation with shuffle and fixed seed for reproducibility\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Store the fold indices for reuse across all embedding method evaluations\n",
        "folds_indices = list(skf.split(np.arange(len(y_common)), y_common))\n"
      ],
      "metadata": {
        "id": "WlKT0kh5shhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contextual Word Embeddings (BERT) with K-Fold Cross-Validation\n",
        "\n",
        "This subsection evaluates the predictive performance of the selected BERT configuration (BERT-base with average pooling of token embeddings) using a 5-fold stratified cross-validation."
      ],
      "metadata": {
        "id": "R8t1Xk_aznbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Additional libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "plt.rcParams.update({'font.size': 16})\n",
        "plt.rcParams.update({'figure.figsize': [10, 6]})\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n"
      ],
      "metadata": {
        "id": "4uz3VwUe_XOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT-base tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load BERT-large tokenizer and model\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
        "# model = BertModel.from_pretrained('bert-large-uncased')"
      ],
      "metadata": {
        "id": "EgUaqe-b_hcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate BERT-based sentence embeddings (mean pooling) for all transcripts\n",
        "bert_embeddings_all = []\n",
        "for text in X_common:\n",
        "    encoding = tokenizer.batch_encode_plus([text],   # List of input texts\n",
        "        padding=True,                                # Pad to the maximum sequence length\n",
        "        truncation=True,                             # Truncate if input exceeds the maximum length\n",
        "        return_tensors='pt',                         # Return PyTorch tensors\n",
        "        add_special_tokens=True                      # Add special CLS and SEP tokens\n",
        "    )\n",
        "    input_ids = encoding['input_ids']                 # Token identifiers\n",
        "    attention_mask = encoding['attention_mask']       # Attention mask\n",
        "    # Generate sentence embeddings using the BERT model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        word_embeddings = outputs.last_hidden_state\n",
        "    sentence_embedding = word_embeddings.mean(dim=1)\n",
        "    bert_embeddings_all.append(sentence_embedding[0])\n",
        "\n",
        "# Convert to NumPy array\n",
        "bert_embeddings_all = np.array(bert_embeddings_all)\n"
      ],
      "metadata": {
        "id": "z2OOPy47zpq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize lists to store metrics for each fold\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Perform 5-fold cross-validation using precomputed fold indices\n",
        "for fold, (train_idx, test_idx) in enumerate(folds_indices):\n",
        "    # Split embeddings and labels for the current fold\n",
        "    X_train, X_test = bert_embeddings_all[train_idx], bert_embeddings_all[test_idx]\n",
        "    y_train, y_test = y_common.iloc[train_idx], y_common.iloc[test_idx]\n",
        "\n",
        "    # Train logistic regression model\n",
        "    clf = LogisticRegression(class_weight='balanced',solver='lbfgs',max_iter=1000)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Predict for the current fold\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Compute metrics\n",
        "    acc = metrics.accuracy_score(y_test, y_pred)\n",
        "    prec = metrics.precision_score(y_test, y_pred, average='macro')\n",
        "    rec = metrics.recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    # Store metrics\n",
        "    accuracies.append(acc)\n",
        "    precisions.append(prec)\n",
        "    recalls.append(rec)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Print classification report\n",
        "    print(f\"Fold {fold + 1} (BERT embeddings):\")\n",
        "    print(metrics.classification_report(y_test, y_pred, target_names=[\"Control\", \"Alzheimer's Indicator\"]))\n",
        "\n",
        "    # Confusion matrix\n",
        "    conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "    labels = [label_map[i] for i in np.unique(y_common)]\n",
        "    df_cm = pd.DataFrame(conf_matrix, columns=labels, index=labels)\n",
        "    df_cm.index.name = 'Ground Truth Labels'\n",
        "    df_cm.columns.name = 'Predicted Labels'\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sn.set(font_scale=1.4)\n",
        "    sn.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt='g', annot_kws={\"size\": 20})\n",
        "    plt.title(f'Confusion Matrix - Fold {fold + 1} (BERT embeddings)')\n",
        "    plt.show()\n",
        "\n",
        "# Compute and print average metrics\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "std_accuracy = np.std(accuracies)\n",
        "mean_precision = np.mean(precisions)\n",
        "std_precision = np.std(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "std_recall = np.std(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "print(\"Summary of Metrics for 5-Fold Cross-Validation (BERT embeddings):\")\n",
        "print(f\"Accuracy:  {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
        "print(f\"Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
        "print(f\"Recall:    {mean_recall:.4f} ± {std_recall:.4f}\")\n",
        "print(f\"F1-score:  {mean_f1:.4f} ± {std_f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "KTDatgs66mMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tf-Idf with K-Fold Cross-Validation\n",
        "\n",
        "This subsection evaluates the performance of a logistic regression classifier trained on Tf-Idf feature vectors using a 5-fold stratified cross-validation. The same data splits used in previous experiments are reused here to ensure consistent and fair comparison across embedding methods.\n"
      ],
      "metadata": {
        "id": "5JbbBbcnXpx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "plt.rcParams.update({'font.size': 16})\n",
        "plt.rcParams.update({'figure.figsize': [10, 6]})\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# Define a pipeline for Tf-Idf + logistic regression\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', LogisticRegression(class_weight='balanced',solver='lbfgs',max_iter=1000))])\n",
        "\n",
        "# Generate Tf-Idf features for all transcripts\n",
        "tfidf_matrix = text_clf.named_steps['tfidf'].fit_transform(text_clf.named_steps['vect'].fit_transform(X_common))\n",
        "\n",
        "# Convert Tf-Idf sparse matrix to dense NumPy array for easier K-Fold slicing\n",
        "tfidf_features_all = tfidf_matrix.toarray()\n",
        "\n"
      ],
      "metadata": {
        "id": "6LTkk8HwX1BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize metric lists for Tf-Idf evaluation\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Iterate through the folds using precomputed indices\n",
        "for fold, (train_index, test_index) in enumerate(folds_indices):\n",
        "    # Split features and labels for the current fold\n",
        "    X_train_fold, X_test_fold = tfidf_features_all[train_index], tfidf_features_all[test_index]\n",
        "    y_train_fold, y_test_fold = y_common.iloc[train_index], y_common.iloc[test_index]\n",
        "\n",
        "    # Train logistic regression model\n",
        "    clf = LogisticRegression(class_weight='balanced',solver='lbfgs',max_iter=1000)\n",
        "    clf.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Predict for the current fold\n",
        "    y_pred_fold = clf.predict(X_test_fold)\n",
        "\n",
        "    # Compute metrics\n",
        "    acc = metrics.accuracy_score(y_test_fold, y_pred_fold)\n",
        "    prec = metrics.precision_score(y_test_fold, y_pred_fold, average='macro')\n",
        "    rec = metrics.recall_score(y_test_fold, y_pred_fold, average='macro')\n",
        "    f1 = metrics.f1_score(y_test_fold, y_pred_fold, average='macro')\n",
        "\n",
        "    # Store results\n",
        "    accuracies.append(acc)\n",
        "    precisions.append(prec)\n",
        "    recalls.append(rec)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Print classification report for current fold\n",
        "    print(f\"Fold {fold + 1} (TF-IDF):\")\n",
        "    print(metrics.classification_report(y_test_fold, y_pred_fold, target_names=[\"Control\", \"Alzheimer's Indicator\"]))\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    conf_matrix = metrics.confusion_matrix(y_test_fold, y_pred_fold)\n",
        "    labels = [label_map[i] for i in np.unique(y_common)]\n",
        "    df_cm = pd.DataFrame(conf_matrix, columns=labels, index=labels)\n",
        "    df_cm.index.name = 'Ground Truth Labels'\n",
        "    df_cm.columns.name = 'Predicted Labels'\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sn.set(font_scale=1.4)\n",
        "    sn.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt='g', annot_kws={\"size\": 20})\n",
        "    plt.title(f'Confusion Matrix - Fold {fold + 1} (TF-IDF)')\n",
        "    plt.show()\n",
        "\n",
        "# Compute and print metric summary\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "std_accuracy = np.std(accuracies)\n",
        "mean_precision = np.mean(precisions)\n",
        "std_precision = np.std(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "std_recall = np.std(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "print(\"Summary of Metrics for 5-Fold Cross-Validation (TF-IDF):\")\n",
        "print(f\"Accuracy:  {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
        "print(f\"Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
        "print(f\"Recall:    {mean_recall:.4f} ± {std_recall:.4f}\")\n",
        "print(f\"F1-score:  {mean_f1:.4f} ± {std_f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "kyinve_ww-NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-Contextual Word Embeddings (GloVe) with K-Fold Cross-Validation\n",
        "\n",
        "This subsection evaluates the performance of sentence embeddings generated using GloVe word embeddings through a 5-fold stratified cross-validation. The same train-test splits used in previous embedding methods are applied to ensure fair comparison."
      ],
      "metadata": {
        "id": "hISbTMTcbAMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GloVe word embeddings from file\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('stopwords')  # Download stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "glove_embeddings_index = {}\n",
        "# IMPORTANT: Modify this path to point to your local copy of the GloVe embeddings file (300-dimensional)\n",
        "with open('/path/to/Glove/glove300.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        glove_embeddings_index[word] = coefs\n",
        "\n",
        "print(f'Found {len(glove_embeddings_index)} word vectors.')"
      ],
      "metadata": {
        "id": "2JOS-j74xk7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute sentence embeddings from GloVe word vectors\n",
        "def sentence_to_vec(text):\n",
        "    words = str(text).lower()\n",
        "    words = word_tokenize(words)\n",
        "    words = [w for w in words if w not in stop_words]   # Remove stopwords\n",
        "    vectors = []\n",
        "    for w in words:\n",
        "        try:\n",
        "            vectors.append(glove_embeddings_index[w])   # Append word embedding\n",
        "        except KeyError:\n",
        "            continue\n",
        "    vectors = np.array(vectors)\n",
        "    summed = vectors.sum(axis=0)\n",
        "    if not isinstance(summed, np.ndarray):\n",
        "        return np.zeros(300)\n",
        "    return summed / np.sqrt((summed ** 2).sum())\n"
      ],
      "metadata": {
        "id": "8C93hlkQbD4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sentence embeddings for the full dataset\n",
        "from tqdm import tqdm\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "glove_embeddings_all = [sentence_to_vec(text) for text in tqdm(X_common)]\n",
        "glove_embeddings_all = np.array(glove_embeddings_all)"
      ],
      "metadata": {
        "id": "7WHiqZczx1VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize metric lists for GloVe evaluation\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Iterate through the folds using precomputed indices\n",
        "for fold, (train_idx, test_idx) in enumerate(folds_indices):\n",
        "    X_train_fold, X_test_fold = glove_embeddings_all[train_idx], glove_embeddings_all[test_idx]\n",
        "    y_train_fold, y_test_fold = y_common.iloc[train_idx], y_common.iloc[test_idx]\n",
        "\n",
        "    # Train logistic regression model\n",
        "    clf = LogisticRegression(class_weight='balanced',solver='lbfgs',max_iter=1000)\n",
        "    clf.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Predict for the current fold\n",
        "    y_pred_fold = clf.predict(X_test_fold)\n",
        "\n",
        "    # Compute metrics\n",
        "    acc = metrics.accuracy_score(y_test_fold, y_pred_fold)\n",
        "    prec = metrics.precision_score(y_test_fold, y_pred_fold, average='macro')\n",
        "    rec = metrics.recall_score(y_test_fold, y_pred_fold, average='macro')\n",
        "    f1 = metrics.f1_score(y_test_fold, y_pred_fold, average='macro')\n",
        "\n",
        "    # Store results\n",
        "    accuracies.append(acc)\n",
        "    precisions.append(prec)\n",
        "    recalls.append(rec)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Classification report\n",
        "    print(f\"Fold {fold+1} (GloVe embeddings):\")\n",
        "    print(metrics.classification_report(y_test_fold, y_pred_fold, target_names=[\"Control\", \"Alzheimer's Indicator\"]))\n",
        "\n",
        "    # Confusion matrix\n",
        "    conf_matrix = metrics.confusion_matrix(y_test_fold, y_pred_fold)\n",
        "    labels = [label_map[i] for i in np.unique(y_common)]\n",
        "    df_cm = pd.DataFrame(conf_matrix, columns=labels, index=labels)\n",
        "    df_cm.index.name = 'Ground Truth Labels'\n",
        "    df_cm.columns.name = 'Predicted Labels'\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sn.set(font_scale=1.4)\n",
        "    sn.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt='g', annot_kws={\"size\": 20})\n",
        "    plt.title(f'Confusion Matrix - Fold {fold + 1} (GloVe embeddings)')\n",
        "    plt.show()\n",
        "\n",
        "# Compute and print metric summary\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "std_accuracy = np.std(accuracies)\n",
        "mean_precision = np.mean(precisions)\n",
        "std_precision = np.std(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "std_recall = np.std(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "print(\"Summary of Metrics for 5-Fold Cross-Validation (GloVe embeddings):\")\n",
        "print(f\"Accuracy:  {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
        "print(f\"Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
        "print(f\"Recall:    {mean_recall:.4f} ± {std_recall:.4f}\")\n",
        "print(f\"F1-score:  {mean_f1:.4f} ± {std_f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "yfg2rRI1yMxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gemma-2B with K-Fold Cross-Validation\n",
        "\n",
        "This subsection evaluates the performance of sentence embeddings generated using the Gemma-2B language model. The same 5-fold stratified cross-validation setup employed in the other embedding methods was used for consistency and fair comparison.\n"
      ],
      "metadata": {
        "id": "LG69OX12dp4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "id": "Oerot02Z0e85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "p10Syt4V0lyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "model_name = \"google/gemma-2b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "vbJTR4sV0vG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Generate Gemma-2B sentence embeddings for all transcripts in X_common\n",
        "gemma_embeddings_all = []\n",
        "for i, text in enumerate(X_common):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        # Mean pooling over token embeddings to obtain a sentence embedding\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    gemma_embeddings_all.append(embeddings[0])\n",
        "\n",
        "# Convert to NumPy array\n",
        "gemma_embeddings_all = np.array(gemma_embeddings_all)\n"
      ],
      "metadata": {
        "id": "8EnlYt_jdszq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required modules for classification and evaluation\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "liB3LEauGeCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize metric lists for Gemma-2B evaluation\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Iterate through stored fold indices\n",
        "for fold, (train_idx, test_idx) in enumerate(folds_indices):\n",
        "    X_train_fold, X_test_fold = gemma_embeddings_all[train_idx], gemma_embeddings_all[test_idx]\n",
        "    y_train_fold, y_test_fold = y_common.iloc[train_idx], y_common.iloc[test_idx]\n",
        "\n",
        "    # Train logistic regression model\n",
        "    clf = LogisticRegression(class_weight='balanced',solver='lbfgs',max_iter=1000)\n",
        "    clf.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Predict for the current fold\n",
        "    y_pred_fold = clf.predict(X_test_fold)\n",
        "\n",
        "    # Compute metrics\n",
        "    acc = metrics.accuracy_score(y_test_fold, y_pred_fold)\n",
        "    prec = metrics.precision_score(y_test_fold, y_pred_fold, average='macro')\n",
        "    rec = metrics.recall_score(y_test_fold, y_pred_fold, average='macro')\n",
        "    f1 = metrics.f1_score(y_test_fold, y_pred_fold, average='macro')\n",
        "\n",
        "    # Store results\n",
        "    accuracies.append(acc)\n",
        "    precisions.append(prec)\n",
        "    recalls.append(rec)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Classification report\n",
        "    print(f\"Fold {fold+1} (Gemma-2B embeddings):\")\n",
        "    print(metrics.classification_report(y_test_fold, y_pred_fold, target_names=[\"Control\", \"Alzheimer's Indicator\"]))\n",
        "\n",
        "    # Confusion matrix\n",
        "    conf_matrix = metrics.confusion_matrix(y_test_fold, y_pred_fold)\n",
        "    labels = [label_map[i] for i in np.unique(y_common)]\n",
        "    df_cm = pd.DataFrame(conf_matrix, columns=labels, index=labels)\n",
        "    df_cm.index.name = 'Ground Truth Labels'\n",
        "    df_cm.columns.name = 'Predicted Labels'\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sn.set(font_scale=1.4)\n",
        "    sn.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt='g', annot_kws={\"size\": 20})\n",
        "    plt.title(f'Confusion Matrix - Fold {fold+1} (Gemma-2B embeddings)')\n",
        "    plt.show()\n",
        "\n",
        "# Compute and print metric summary\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "std_accuracy = np.std(accuracies)\n",
        "mean_precision = np.mean(precisions)\n",
        "std_precision = np.std(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "std_recall = np.std(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "print(\"Summary of Metrics for 5-Fold Cross-Validation (Gemma-2B embeddings):\")\n",
        "print(f\"Accuracy:  {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
        "print(f\"Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
        "print(f\"Recall:    {mean_recall:.4f} ± {std_recall:.4f}\")\n",
        "print(f\"F1-score:  {mean_f1:.4f} ± {std_f1:.4f}\")"
      ],
      "metadata": {
        "id": "t44ktDqs0-3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}